client:495 [vite] connecting...
client:618 [vite] connected.
whisperWebGPU.js:18 [WhisperWebGPU] Browser cache enabled for model persistence
installHook.js:1 ‚ö†Ô∏è React Router Future Flag Warning: React Router will begin wrapping state updates in `React.startTransition` in v7. You can use the `v7_startTransition` future flag to opt-in early. For more information, see https://reactrouter.com/v6/upgrading/future#v7_starttransition. Error Component Stack
    at BrowserRouter (react-router-dom.js?v=e2aba83d:5247:5)
    at App (<anonymous>)
overrideMethod @ installHook.js:1
warnOnce @ react-router-dom.js?v=e2aba83d:4393
logDeprecation @ react-router-dom.js?v=e2aba83d:4396
logV6DeprecationWarnings @ react-router-dom.js?v=e2aba83d:4399
(anonymous) @ react-router-dom.js?v=e2aba83d:5271
commitHookEffectListMount @ chunk-YZVM2MHU.js?v=e2aba83d:16915
commitPassiveMountOnFiber @ chunk-YZVM2MHU.js?v=e2aba83d:18156
commitPassiveMountEffects_complete @ chunk-YZVM2MHU.js?v=e2aba83d:18129
commitPassiveMountEffects_begin @ chunk-YZVM2MHU.js?v=e2aba83d:18119
commitPassiveMountEffects @ chunk-YZVM2MHU.js?v=e2aba83d:18109
flushPassiveEffectsImpl @ chunk-YZVM2MHU.js?v=e2aba83d:19490
flushPassiveEffects @ chunk-YZVM2MHU.js?v=e2aba83d:19447
(anonymous) @ chunk-YZVM2MHU.js?v=e2aba83d:19328
workLoop @ chunk-YZVM2MHU.js?v=e2aba83d:197
flushWork @ chunk-YZVM2MHU.js?v=e2aba83d:176
performWorkUntilDeadline @ chunk-YZVM2MHU.js?v=e2aba83d:384
installHook.js:1 ‚ö†Ô∏è React Router Future Flag Warning: Relative route resolution within Splat routes is changing in v7. You can use the `v7_relativeSplatPath` future flag to opt-in early. For more information, see https://reactrouter.com/v6/upgrading/future#v7_relativesplatpath. Error Component Stack
    at BrowserRouter (react-router-dom.js?v=e2aba83d:5247:5)
    at App (<anonymous>)
overrideMethod @ installHook.js:1
warnOnce @ react-router-dom.js?v=e2aba83d:4393
logDeprecation @ react-router-dom.js?v=e2aba83d:4396
logV6DeprecationWarnings @ react-router-dom.js?v=e2aba83d:4402
(anonymous) @ react-router-dom.js?v=e2aba83d:5271
commitHookEffectListMount @ chunk-YZVM2MHU.js?v=e2aba83d:16915
commitPassiveMountOnFiber @ chunk-YZVM2MHU.js?v=e2aba83d:18156
commitPassiveMountEffects_complete @ chunk-YZVM2MHU.js?v=e2aba83d:18129
commitPassiveMountEffects_begin @ chunk-YZVM2MHU.js?v=e2aba83d:18119
commitPassiveMountEffects @ chunk-YZVM2MHU.js?v=e2aba83d:18109
flushPassiveEffectsImpl @ chunk-YZVM2MHU.js?v=e2aba83d:19490
flushPassiveEffects @ chunk-YZVM2MHU.js?v=e2aba83d:19447
(anonymous) @ chunk-YZVM2MHU.js?v=e2aba83d:19328
workLoop @ chunk-YZVM2MHU.js?v=e2aba83d:197
flushWork @ chunk-YZVM2MHU.js?v=e2aba83d:176
performWorkUntilDeadline @ chunk-YZVM2MHU.js?v=e2aba83d:384
[Violation] Forced reflow while executing JavaScript took <N>ms
[Violation] Forced reflow while executing JavaScript took <N>ms
[Violation] Forced reflow while executing JavaScript took <N>ms
[Violation] Forced reflow while executing JavaScript took <N>ms
[Violation] Forced reflow while executing JavaScript took <N>ms
[Violation] Forced reflow while executing JavaScript took <N>ms
webllm.js:109 üìã [TASK] Initializing AI Engine (Llama-3.2-1B-Instruct-q4f32_1-MLC)... 
hardwareCheck.js:19 [HardwareCheck] Max Buffer Size: 2048.00 MB
webllm.js:109 ‚ÑπÔ∏è [INFO] Hardware Tier: medium 
webllm.js:109 ‚ÑπÔ∏è [INFO] Auto-selected model for medium tier hardware: Llama-3.2-1B-Instruct-q4f32_1-MLC 
webllm.js:109 ‚úÖ [SUCCESS] ‚úÖ Found cached model: Llama-3.2-1B-Instruct-q4f32_1-MLC. Loading from cache... 
The powerPreference option is currently ignored when calling requestAdapter() on Windows. See https://crbug.com/369219127
:3000/chat:1 The powerPreference option is currently ignored when calling requestAdapter() on Windows. See https://crbug.com/369219127
webllm.js:109 ‚úÖ [SUCCESS] ‚úÖ Model initialized successfully and ready to use! 
webllm.js:109 ‚ÑπÔ∏è [INFO] Token usage - Prompt: 124, Completion: 30, Total: 154 
VoiceContext.jsx:59 [VoiceContext] Initializing voice models...
VoiceContext.jsx:102 [VoiceContext] Cleaning up voice models...
modelOrchestrator.js:123 ‚úÖ Not on Voice Therapy tab, no action needed
audioRecorder.js:326 üóëÔ∏è Audio recorder cleaned up
voicePipeline.js:434 üóëÔ∏è Voice pipeline cleaned up
VoiceContext.jsx:117 ‚úÖ [VoiceContext] Voice models cleaned up
voiceSessionStorage.js:42 [VoiceStorage] Database opened successfully
modelOrchestrator.js:53 [ModelOrchestrator] Switching to Voice Therapy tab...
modelOrchestrator.js:58 [ModelOrchestrator] WebLLM not loaded, will initialize after voice models
modelOrchestrator.js:68 [ModelOrchestrator] Loading Whisper WebGPU (tiny.en)...
whisperWebGPU.js:82 [WhisperWebGPU] ‚úÖ WebGPU is available
whisperWebGPU.js:116 [WhisperWebGPU] WebGPU available: true, using device: wasm
whisperWebGPU.js:124 [WhisperWebGPU] Loading Whisper Tiny English (39MB) with WASM...
modelOrchestrator.js:71 [ModelOrchestrator] Loading Whisper Tiny English... (10%)
whisperWebGPU.js:169 [WhisperWebGPU] ‚Üì Downloading tokenizer.json...
whisperWebGPU.js:169 [WhisperWebGPU] ‚Üì Downloading tokenizer_config.json...
whisperWebGPU.js:169 [WhisperWebGPU] ‚Üì Downloading config.json...
whisperWebGPU.js:169 [WhisperWebGPU] ‚Üì Downloading preprocessor_config.json...
installHook.js:1 Unable to determine content-length from response headers. Will expand buffer when needed.
overrideMethod @ installHook.js:1
readResponse @ @huggingface_transformers.js?v=e2aba83d:29807
getModelFile @ @huggingface_transformers.js?v=e2aba83d:29724
await in getModelFile
getModelText @ @huggingface_transformers.js?v=e2aba83d:29787
getModelJSON @ @huggingface_transformers.js?v=e2aba83d:29798
loadTokenizer @ @huggingface_transformers.js?v=e2aba83d:24675
from_pretrained @ @huggingface_transformers.js?v=e2aba83d:27796
loadItems @ @huggingface_transformers.js?v=e2aba83d:24372
pipeline @ @huggingface_transformers.js?v=e2aba83d:24330
initialize @ whisperWebGPU.js:139
await in initialize
switchToVoiceTab @ modelOrchestrator.js:70
await in switchToVoiceTab
(anonymous) @ VoiceContext.jsx:67
await in (anonymous)
(anonymous) @ VoiceTherapy.jsx:46
commitHookEffectListMount @ chunk-YZVM2MHU.js?v=e2aba83d:16915
commitPassiveMountOnFiber @ chunk-YZVM2MHU.js?v=e2aba83d:18156
commitPassiveMountEffects_complete @ chunk-YZVM2MHU.js?v=e2aba83d:18129
commitPassiveMountEffects_begin @ chunk-YZVM2MHU.js?v=e2aba83d:18119
commitPassiveMountEffects @ chunk-YZVM2MHU.js?v=e2aba83d:18109
flushPassiveEffectsImpl @ chunk-YZVM2MHU.js?v=e2aba83d:19490
flushPassiveEffects @ chunk-YZVM2MHU.js?v=e2aba83d:19447
commitRootImpl @ chunk-YZVM2MHU.js?v=e2aba83d:19416
commitRoot @ chunk-YZVM2MHU.js?v=e2aba83d:19277
performSyncWorkOnRoot @ chunk-YZVM2MHU.js?v=e2aba83d:18895
flushSyncCallbacks @ chunk-YZVM2MHU.js?v=e2aba83d:9119
(anonymous) @ chunk-YZVM2MHU.js?v=e2aba83d:18627
installHook.js:1 Unable to determine content-length from response headers. Will expand buffer when needed.
overrideMethod @ installHook.js:1
readResponse @ @huggingface_transformers.js?v=e2aba83d:29807
getModelFile @ @huggingface_transformers.js?v=e2aba83d:29724
await in getModelFile
getModelText @ @huggingface_transformers.js?v=e2aba83d:29787
getModelJSON @ @huggingface_transformers.js?v=e2aba83d:29798
loadTokenizer @ @huggingface_transformers.js?v=e2aba83d:24676
from_pretrained @ @huggingface_transformers.js?v=e2aba83d:27796
loadItems @ @huggingface_transformers.js?v=e2aba83d:24372
pipeline @ @huggingface_transformers.js?v=e2aba83d:24330
initialize @ whisperWebGPU.js:139
await in initialize
switchToVoiceTab @ modelOrchestrator.js:70
await in switchToVoiceTab
(anonymous) @ VoiceContext.jsx:67
await in (anonymous)
(anonymous) @ VoiceTherapy.jsx:46
commitHookEffectListMount @ chunk-YZVM2MHU.js?v=e2aba83d:16915
commitPassiveMountOnFiber @ chunk-YZVM2MHU.js?v=e2aba83d:18156
commitPassiveMountEffects_complete @ chunk-YZVM2MHU.js?v=e2aba83d:18129
commitPassiveMountEffects_begin @ chunk-YZVM2MHU.js?v=e2aba83d:18119
commitPassiveMountEffects @ chunk-YZVM2MHU.js?v=e2aba83d:18109
flushPassiveEffectsImpl @ chunk-YZVM2MHU.js?v=e2aba83d:19490
flushPassiveEffects @ chunk-YZVM2MHU.js?v=e2aba83d:19447
commitRootImpl @ chunk-YZVM2MHU.js?v=e2aba83d:19416
commitRoot @ chunk-YZVM2MHU.js?v=e2aba83d:19277
performSyncWorkOnRoot @ chunk-YZVM2MHU.js?v=e2aba83d:18895
flushSyncCallbacks @ chunk-YZVM2MHU.js?v=e2aba83d:9119
(anonymous) @ chunk-YZVM2MHU.js?v=e2aba83d:18627
installHook.js:1 Unable to determine content-length from response headers. Will expand buffer when needed.
overrideMethod @ installHook.js:1
readResponse @ @huggingface_transformers.js?v=e2aba83d:29807
getModelFile @ @huggingface_transformers.js?v=e2aba83d:29724
await in getModelFile
getModelText @ @huggingface_transformers.js?v=e2aba83d:29787
getModelJSON @ @huggingface_transformers.js?v=e2aba83d:29798
loadConfig @ @huggingface_transformers.js?v=e2aba83d:5194
from_pretrained @ @huggingface_transformers.js?v=e2aba83d:5501
from_pretrained @ @huggingface_transformers.js?v=e2aba83d:5514
from_pretrained @ @huggingface_transformers.js?v=e2aba83d:15176
(anonymous) @ @huggingface_transformers.js?v=e2aba83d:24356
loadItems @ @huggingface_transformers.js?v=e2aba83d:24347
pipeline @ @huggingface_transformers.js?v=e2aba83d:24330
initialize @ whisperWebGPU.js:139
await in initialize
switchToVoiceTab @ modelOrchestrator.js:70
await in switchToVoiceTab
(anonymous) @ VoiceContext.jsx:67
await in (anonymous)
(anonymous) @ VoiceTherapy.jsx:46
commitHookEffectListMount @ chunk-YZVM2MHU.js?v=e2aba83d:16915
commitPassiveMountOnFiber @ chunk-YZVM2MHU.js?v=e2aba83d:18156
commitPassiveMountEffects_complete @ chunk-YZVM2MHU.js?v=e2aba83d:18129
commitPassiveMountEffects_begin @ chunk-YZVM2MHU.js?v=e2aba83d:18119
commitPassiveMountEffects @ chunk-YZVM2MHU.js?v=e2aba83d:18109
flushPassiveEffectsImpl @ chunk-YZVM2MHU.js?v=e2aba83d:19490
flushPassiveEffects @ chunk-YZVM2MHU.js?v=e2aba83d:19447
commitRootImpl @ chunk-YZVM2MHU.js?v=e2aba83d:19416
commitRoot @ chunk-YZVM2MHU.js?v=e2aba83d:19277
performSyncWorkOnRoot @ chunk-YZVM2MHU.js?v=e2aba83d:18895
flushSyncCallbacks @ chunk-YZVM2MHU.js?v=e2aba83d:9119
(anonymous) @ chunk-YZVM2MHU.js?v=e2aba83d:18627
whisperWebGPU.js:154 [WhisperWebGPU] tokenizer.json: 100%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading tokenizer.json: 100% (90%)
whisperWebGPU.js:165 [WhisperWebGPU] ‚úì tokenizer.json ready
modelOrchestrator.js:71 [ModelOrchestrator] Loading model components... (92%)
whisperWebGPU.js:165 [WhisperWebGPU] ‚úì tokenizer_config.json ready
modelOrchestrator.js:71 [ModelOrchestrator] Loading model components... (92%)
whisperWebGPU.js:165 [WhisperWebGPU] ‚úì config.json ready
modelOrchestrator.js:71 [ModelOrchestrator] Loading model components... (92%)
whisperWebGPU.js:169 [WhisperWebGPU] ‚Üì Downloading encoder_model_quantized.onnx...
whisperWebGPU.js:169 [WhisperWebGPU] ‚Üì Downloading decoder_model_merged_quantized.onnx...
whisperWebGPU.js:169 [WhisperWebGPU] ‚Üì Downloading generation_config.json...
whisperWebGPU.js:165 [WhisperWebGPU] ‚úì preprocessor_config.json ready
modelOrchestrator.js:71 [ModelOrchestrator] Loading model components... (92%)
whisperWebGPU.js:169 [WhisperWebGPU] ‚Üì Downloading tokenizer.json...
whisperWebGPU.js:169 [WhisperWebGPU] ‚Üì Downloading tokenizer_config.json...
whisperWebGPU.js:169 [WhisperWebGPU] ‚Üì Downloading preprocessor_config.json...
installHook.js:1 Unable to determine content-length from response headers. Will expand buffer when needed.
overrideMethod @ installHook.js:1
readResponse @ @huggingface_transformers.js?v=e2aba83d:29807
getModelFile @ @huggingface_transformers.js?v=e2aba83d:29724
await in getModelFile
getModelText @ @huggingface_transformers.js?v=e2aba83d:29787
getModelJSON @ @huggingface_transformers.js?v=e2aba83d:29798
loadTokenizer @ @huggingface_transformers.js?v=e2aba83d:24676
from_pretrained @ @huggingface_transformers.js?v=e2aba83d:27796
(anonymous) @ @huggingface_transformers.js?v=e2aba83d:5141
from_pretrained @ @huggingface_transformers.js?v=e2aba83d:5140
from_pretrained @ @huggingface_transformers.js?v=e2aba83d:16207
await in from_pretrained
loadItems @ @huggingface_transformers.js?v=e2aba83d:24372
pipeline @ @huggingface_transformers.js?v=e2aba83d:24330
initialize @ whisperWebGPU.js:139
await in initialize
switchToVoiceTab @ modelOrchestrator.js:70
await in switchToVoiceTab
(anonymous) @ VoiceContext.jsx:67
await in (anonymous)
(anonymous) @ VoiceTherapy.jsx:46
commitHookEffectListMount @ chunk-YZVM2MHU.js?v=e2aba83d:16915
commitPassiveMountOnFiber @ chunk-YZVM2MHU.js?v=e2aba83d:18156
commitPassiveMountEffects_complete @ chunk-YZVM2MHU.js?v=e2aba83d:18129
commitPassiveMountEffects_begin @ chunk-YZVM2MHU.js?v=e2aba83d:18119
commitPassiveMountEffects @ chunk-YZVM2MHU.js?v=e2aba83d:18109
flushPassiveEffectsImpl @ chunk-YZVM2MHU.js?v=e2aba83d:19490
flushPassiveEffects @ chunk-YZVM2MHU.js?v=e2aba83d:19447
commitRootImpl @ chunk-YZVM2MHU.js?v=e2aba83d:19416
commitRoot @ chunk-YZVM2MHU.js?v=e2aba83d:19277
performSyncWorkOnRoot @ chunk-YZVM2MHU.js?v=e2aba83d:18895
flushSyncCallbacks @ chunk-YZVM2MHU.js?v=e2aba83d:9119
(anonymous) @ chunk-YZVM2MHU.js?v=e2aba83d:18627
installHook.js:1 Unable to determine content-length from response headers. Will expand buffer when needed.
overrideMethod @ installHook.js:1
readResponse @ @huggingface_transformers.js?v=e2aba83d:29807
getModelFile @ @huggingface_transformers.js?v=e2aba83d:29724
await in getModelFile
getModelText @ @huggingface_transformers.js?v=e2aba83d:29787
getModelJSON @ @huggingface_transformers.js?v=e2aba83d:29798
(anonymous) @ @huggingface_transformers.js?v=e2aba83d:10429
getOptionalConfigs @ @huggingface_transformers.js?v=e2aba83d:10428
from_pretrained @ @huggingface_transformers.js?v=e2aba83d:10962
await in from_pretrained
from_pretrained @ @huggingface_transformers.js?v=e2aba83d:15192
await in from_pretrained
(anonymous) @ @huggingface_transformers.js?v=e2aba83d:24356
loadItems @ @huggingface_transformers.js?v=e2aba83d:24347
pipeline @ @huggingface_transformers.js?v=e2aba83d:24330
initialize @ whisperWebGPU.js:139
await in initialize
switchToVoiceTab @ modelOrchestrator.js:70
await in switchToVoiceTab
(anonymous) @ VoiceContext.jsx:67
await in (anonymous)
(anonymous) @ VoiceTherapy.jsx:46
commitHookEffectListMount @ chunk-YZVM2MHU.js?v=e2aba83d:16915
commitPassiveMountOnFiber @ chunk-YZVM2MHU.js?v=e2aba83d:18156
commitPassiveMountEffects_complete @ chunk-YZVM2MHU.js?v=e2aba83d:18129
commitPassiveMountEffects_begin @ chunk-YZVM2MHU.js?v=e2aba83d:18119
commitPassiveMountEffects @ chunk-YZVM2MHU.js?v=e2aba83d:18109
flushPassiveEffectsImpl @ chunk-YZVM2MHU.js?v=e2aba83d:19490
flushPassiveEffects @ chunk-YZVM2MHU.js?v=e2aba83d:19447
commitRootImpl @ chunk-YZVM2MHU.js?v=e2aba83d:19416
commitRoot @ chunk-YZVM2MHU.js?v=e2aba83d:19277
performSyncWorkOnRoot @ chunk-YZVM2MHU.js?v=e2aba83d:18895
flushSyncCallbacks @ chunk-YZVM2MHU.js?v=e2aba83d:9119
(anonymous) @ chunk-YZVM2MHU.js?v=e2aba83d:18627
installHook.js:1 Unable to determine content-length from response headers. Will expand buffer when needed.
overrideMethod @ installHook.js:1
readResponse @ @huggingface_transformers.js?v=e2aba83d:29807
getModelFile @ @huggingface_transformers.js?v=e2aba83d:29724
await in getModelFile
getModelText @ @huggingface_transformers.js?v=e2aba83d:29787
getModelJSON @ @huggingface_transformers.js?v=e2aba83d:29798
loadTokenizer @ @huggingface_transformers.js?v=e2aba83d:24675
from_pretrained @ @huggingface_transformers.js?v=e2aba83d:27796
(anonymous) @ @huggingface_transformers.js?v=e2aba83d:5141
from_pretrained @ @huggingface_transformers.js?v=e2aba83d:5140
from_pretrained @ @huggingface_transformers.js?v=e2aba83d:16207
await in from_pretrained
loadItems @ @huggingface_transformers.js?v=e2aba83d:24372
pipeline @ @huggingface_transformers.js?v=e2aba83d:24330
initialize @ whisperWebGPU.js:139
await in initialize
switchToVoiceTab @ modelOrchestrator.js:70
await in switchToVoiceTab
(anonymous) @ VoiceContext.jsx:67
await in (anonymous)
(anonymous) @ VoiceTherapy.jsx:46
commitHookEffectListMount @ chunk-YZVM2MHU.js?v=e2aba83d:16915
commitPassiveMountOnFiber @ chunk-YZVM2MHU.js?v=e2aba83d:18156
commitPassiveMountEffects_complete @ chunk-YZVM2MHU.js?v=e2aba83d:18129
commitPassiveMountEffects_begin @ chunk-YZVM2MHU.js?v=e2aba83d:18119
commitPassiveMountEffects @ chunk-YZVM2MHU.js?v=e2aba83d:18109
flushPassiveEffectsImpl @ chunk-YZVM2MHU.js?v=e2aba83d:19490
flushPassiveEffects @ chunk-YZVM2MHU.js?v=e2aba83d:19447
commitRootImpl @ chunk-YZVM2MHU.js?v=e2aba83d:19416
commitRoot @ chunk-YZVM2MHU.js?v=e2aba83d:19277
performSyncWorkOnRoot @ chunk-YZVM2MHU.js?v=e2aba83d:18895
flushSyncCallbacks @ chunk-YZVM2MHU.js?v=e2aba83d:9119
(anonymous) @ chunk-YZVM2MHU.js?v=e2aba83d:18627
whisperWebGPU.js:154 [WhisperWebGPU] decoder_model_merged_quantized.onnx: 4%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading decoder_model_merged_quantized.onnx: 4% (13.2%)
whisperWebGPU.js:154 [WhisperWebGPU] decoder_model_merged_quantized.onnx: 7%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading decoder_model_merged_quantized.onnx: 7% (15.600000000000001%)
whisperWebGPU.js:154 [WhisperWebGPU] decoder_model_merged_quantized.onnx: 12%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading decoder_model_merged_quantized.onnx: 12% (19.6%)
whisperWebGPU.js:154 [WhisperWebGPU] decoder_model_merged_quantized.onnx: 14%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading decoder_model_merged_quantized.onnx: 14% (21.200000000000003%)
whisperWebGPU.js:154 [WhisperWebGPU] decoder_model_merged_quantized.onnx: 18%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading decoder_model_merged_quantized.onnx: 18% (24.4%)
whisperWebGPU.js:154 [WhisperWebGPU] decoder_model_merged_quantized.onnx: 20%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading decoder_model_merged_quantized.onnx: 20% (26%)
whisperWebGPU.js:154 [WhisperWebGPU] decoder_model_merged_quantized.onnx: 24%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading decoder_model_merged_quantized.onnx: 24% (29.200000000000003%)
whisperWebGPU.js:154 [WhisperWebGPU] decoder_model_merged_quantized.onnx: 27%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading decoder_model_merged_quantized.onnx: 27% (31.6%)
whisperWebGPU.js:154 [WhisperWebGPU] decoder_model_merged_quantized.onnx: 30%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading decoder_model_merged_quantized.onnx: 30% (34%)
whisperWebGPU.js:154 [WhisperWebGPU] decoder_model_merged_quantized.onnx: 32%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading decoder_model_merged_quantized.onnx: 32% (35.6%)
whisperWebGPU.js:154 [WhisperWebGPU] decoder_model_merged_quantized.onnx: 34%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading decoder_model_merged_quantized.onnx: 34% (37.2%)
whisperWebGPU.js:154 [WhisperWebGPU] decoder_model_merged_quantized.onnx: 36%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading decoder_model_merged_quantized.onnx: 36% (38.8%)
whisperWebGPU.js:154 [WhisperWebGPU] decoder_model_merged_quantized.onnx: 39%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading decoder_model_merged_quantized.onnx: 39% (41.2%)
whisperWebGPU.js:154 [WhisperWebGPU] decoder_model_merged_quantized.onnx: 41%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading decoder_model_merged_quantized.onnx: 41% (42.800000000000004%)
whisperWebGPU.js:154 [WhisperWebGPU] decoder_model_merged_quantized.onnx: 43%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading decoder_model_merged_quantized.onnx: 43% (44.4%)
whisperWebGPU.js:154 [WhisperWebGPU] decoder_model_merged_quantized.onnx: 45%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading decoder_model_merged_quantized.onnx: 45% (46%)
whisperWebGPU.js:154 [WhisperWebGPU] decoder_model_merged_quantized.onnx: 47%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading decoder_model_merged_quantized.onnx: 47% (47.6%)
whisperWebGPU.js:154 [WhisperWebGPU] decoder_model_merged_quantized.onnx: 48%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading decoder_model_merged_quantized.onnx: 48% (48.400000000000006%)
whisperWebGPU.js:154 [WhisperWebGPU] decoder_model_merged_quantized.onnx: 49%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading decoder_model_merged_quantized.onnx: 49% (49.2%)
whisperWebGPU.js:154 [WhisperWebGPU] decoder_model_merged_quantized.onnx: 50%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading decoder_model_merged_quantized.onnx: 50% (50%)
whisperWebGPU.js:154 [WhisperWebGPU] decoder_model_merged_quantized.onnx: 51%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading decoder_model_merged_quantized.onnx: 51% (50.800000000000004%)
whisperWebGPU.js:154 [WhisperWebGPU] decoder_model_merged_quantized.onnx: 52%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading decoder_model_merged_quantized.onnx: 52% (51.6%)
whisperWebGPU.js:154 [WhisperWebGPU] decoder_model_merged_quantized.onnx: 54%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading decoder_model_merged_quantized.onnx: 54% (53.2%)
whisperWebGPU.js:154 [WhisperWebGPU] decoder_model_merged_quantized.onnx: 55%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading decoder_model_merged_quantized.onnx: 55% (54%)
whisperWebGPU.js:154 [WhisperWebGPU] decoder_model_merged_quantized.onnx: 56%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading decoder_model_merged_quantized.onnx: 56% (54.800000000000004%)
whisperWebGPU.js:154 [WhisperWebGPU] decoder_model_merged_quantized.onnx: 58%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading decoder_model_merged_quantized.onnx: 58% (56.400000000000006%)
whisperWebGPU.js:154 [WhisperWebGPU] decoder_model_merged_quantized.onnx: 59%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading decoder_model_merged_quantized.onnx: 59% (57.2%)
whisperWebGPU.js:154 [WhisperWebGPU] decoder_model_merged_quantized.onnx: 60%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading decoder_model_merged_quantized.onnx: 60% (58%)
whisperWebGPU.js:154 [WhisperWebGPU] decoder_model_merged_quantized.onnx: 61%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading decoder_model_merged_quantized.onnx: 61% (58.800000000000004%)
whisperWebGPU.js:154 [WhisperWebGPU] decoder_model_merged_quantized.onnx: 64%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading decoder_model_merged_quantized.onnx: 64% (61.2%)
whisperWebGPU.js:154 [WhisperWebGPU] decoder_model_merged_quantized.onnx: 65%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading decoder_model_merged_quantized.onnx: 65% (62%)
whisperWebGPU.js:154 [WhisperWebGPU] decoder_model_merged_quantized.onnx: 66%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading decoder_model_merged_quantized.onnx: 66% (62.800000000000004%)
whisperWebGPU.js:154 [WhisperWebGPU] decoder_model_merged_quantized.onnx: 67%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading decoder_model_merged_quantized.onnx: 67% (63.6%)
whisperWebGPU.js:154 [WhisperWebGPU] decoder_model_merged_quantized.onnx: 68%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading decoder_model_merged_quantized.onnx: 68% (64.4%)
whisperWebGPU.js:154 [WhisperWebGPU] decoder_model_merged_quantized.onnx: 70%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading decoder_model_merged_quantized.onnx: 70% (66%)
whisperWebGPU.js:154 [WhisperWebGPU] decoder_model_merged_quantized.onnx: 72%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading decoder_model_merged_quantized.onnx: 72% (67.6%)
whisperWebGPU.js:154 [WhisperWebGPU] decoder_model_merged_quantized.onnx: 74%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading decoder_model_merged_quantized.onnx: 74% (69.2%)
whisperWebGPU.js:154 [WhisperWebGPU] decoder_model_merged_quantized.onnx: 75%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading decoder_model_merged_quantized.onnx: 75% (70%)
whisperWebGPU.js:154 [WhisperWebGPU] decoder_model_merged_quantized.onnx: 77%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading decoder_model_merged_quantized.onnx: 77% (71.6%)
whisperWebGPU.js:154 [WhisperWebGPU] decoder_model_merged_quantized.onnx: 79%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading decoder_model_merged_quantized.onnx: 79% (73.2%)
whisperWebGPU.js:154 [WhisperWebGPU] decoder_model_merged_quantized.onnx: 81%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading decoder_model_merged_quantized.onnx: 81% (74.8%)
whisperWebGPU.js:154 [WhisperWebGPU] decoder_model_merged_quantized.onnx: 82%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading decoder_model_merged_quantized.onnx: 82% (75.60000000000001%)
whisperWebGPU.js:154 [WhisperWebGPU] decoder_model_merged_quantized.onnx: 83%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading decoder_model_merged_quantized.onnx: 83% (76.4%)
whisperWebGPU.js:154 [WhisperWebGPU] decoder_model_merged_quantized.onnx: 85%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading decoder_model_merged_quantized.onnx: 85% (78%)
whisperWebGPU.js:154 [WhisperWebGPU] decoder_model_merged_quantized.onnx: 87%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading decoder_model_merged_quantized.onnx: 87% (79.60000000000001%)
whisperWebGPU.js:154 [WhisperWebGPU] decoder_model_merged_quantized.onnx: 89%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading decoder_model_merged_quantized.onnx: 89% (81.2%)
whisperWebGPU.js:154 [WhisperWebGPU] decoder_model_merged_quantized.onnx: 95%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading decoder_model_merged_quantized.onnx: 95% (86%)
whisperWebGPU.js:154 [WhisperWebGPU] decoder_model_merged_quantized.onnx: 96%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading decoder_model_merged_quantized.onnx: 96% (86.80000000000001%)
whisperWebGPU.js:154 [WhisperWebGPU] decoder_model_merged_quantized.onnx: 97%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading decoder_model_merged_quantized.onnx: 97% (87.60000000000001%)
whisperWebGPU.js:154 [WhisperWebGPU] decoder_model_merged_quantized.onnx: 99%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading decoder_model_merged_quantized.onnx: 99% (89.2%)
whisperWebGPU.js:154 [WhisperWebGPU] decoder_model_merged_quantized.onnx: 100%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading decoder_model_merged_quantized.onnx: 100% (90%)
whisperWebGPU.js:165 [WhisperWebGPU] ‚úì tokenizer_config.json ready
modelOrchestrator.js:71 [ModelOrchestrator] Loading model components... (92%)
whisperWebGPU.js:154 [WhisperWebGPU] encoder_model_quantized.onnx: 21%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading encoder_model_quantized.onnx: 21% (26.8%)
whisperWebGPU.js:154 [WhisperWebGPU] encoder_model_quantized.onnx: 28%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading encoder_model_quantized.onnx: 28% (32.400000000000006%)
whisperWebGPU.js:154 [WhisperWebGPU] encoder_model_quantized.onnx: 34%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading encoder_model_quantized.onnx: 34% (37.2%)
whisperWebGPU.js:154 [WhisperWebGPU] encoder_model_quantized.onnx: 38%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading encoder_model_quantized.onnx: 38% (40.400000000000006%)
whisperWebGPU.js:154 [WhisperWebGPU] encoder_model_quantized.onnx: 39%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading encoder_model_quantized.onnx: 39% (41.2%)
whisperWebGPU.js:154 [WhisperWebGPU] encoder_model_quantized.onnx: 41%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading encoder_model_quantized.onnx: 41% (42.800000000000004%)
whisperWebGPU.js:154 [WhisperWebGPU] encoder_model_quantized.onnx: 43%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading encoder_model_quantized.onnx: 43% (44.4%)
whisperWebGPU.js:154 [WhisperWebGPU] encoder_model_quantized.onnx: 45%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading encoder_model_quantized.onnx: 45% (46%)
whisperWebGPU.js:154 [WhisperWebGPU] encoder_model_quantized.onnx: 47%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading encoder_model_quantized.onnx: 47% (47.6%)
whisperWebGPU.js:154 [WhisperWebGPU] encoder_model_quantized.onnx: 51%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading encoder_model_quantized.onnx: 51% (50.800000000000004%)
whisperWebGPU.js:154 [WhisperWebGPU] encoder_model_quantized.onnx: 54%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading encoder_model_quantized.onnx: 54% (53.2%)
whisperWebGPU.js:154 [WhisperWebGPU] encoder_model_quantized.onnx: 56%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading encoder_model_quantized.onnx: 56% (54.800000000000004%)
whisperWebGPU.js:154 [WhisperWebGPU] encoder_model_quantized.onnx: 59%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading encoder_model_quantized.onnx: 59% (57.2%)
whisperWebGPU.js:154 [WhisperWebGPU] preprocessor_config.json: 100%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading preprocessor_config.json: 100% (90%)
whisperWebGPU.js:165 [WhisperWebGPU] ‚úì decoder_model_merged_quantized.onnx ready
modelOrchestrator.js:71 [ModelOrchestrator] Loading model components... (92%)
whisperWebGPU.js:165 [WhisperWebGPU] ‚úì generation_config.json ready
modelOrchestrator.js:71 [ModelOrchestrator] Loading model components... (92%)
whisperWebGPU.js:165 [WhisperWebGPU] ‚úì tokenizer.json ready
modelOrchestrator.js:71 [ModelOrchestrator] Loading model components... (92%)
whisperWebGPU.js:165 [WhisperWebGPU] ‚úì preprocessor_config.json ready
modelOrchestrator.js:71 [ModelOrchestrator] Loading model components... (92%)
whisperWebGPU.js:154 [WhisperWebGPU] encoder_model_quantized.onnx: 62%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading encoder_model_quantized.onnx: 62% (59.6%)
whisperWebGPU.js:154 [WhisperWebGPU] encoder_model_quantized.onnx: 82%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading encoder_model_quantized.onnx: 82% (75.60000000000001%)
whisperWebGPU.js:154 [WhisperWebGPU] encoder_model_quantized.onnx: 83%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading encoder_model_quantized.onnx: 83% (76.4%)
whisperWebGPU.js:154 [WhisperWebGPU] encoder_model_quantized.onnx: 89%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading encoder_model_quantized.onnx: 89% (81.2%)
whisperWebGPU.js:154 [WhisperWebGPU] encoder_model_quantized.onnx: 94%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading encoder_model_quantized.onnx: 94% (85.2%)
whisperWebGPU.js:154 [WhisperWebGPU] encoder_model_quantized.onnx: 100%
modelOrchestrator.js:71 [ModelOrchestrator] Downloading encoder_model_quantized.onnx: 100% (90%)
whisperWebGPU.js:165 [WhisperWebGPU] ‚úì encoder_model_quantized.onnx ready
modelOrchestrator.js:71 [ModelOrchestrator] Loading model components... (92%)
whisperWebGPU.js:181 [WhisperWebGPU] ‚úÖ Initialized with WASM
modelOrchestrator.js:71 [ModelOrchestrator] Ready! (100%)
modelOrchestrator.js:77 ‚úÖ Whisper loaded with WASM acceleration
modelOrchestrator.js:89 [ModelOrchestrator] Loading Piper TTS...
piper.js:87 üì• Loading Piper voice: Lessac (Female, US) (30MB)
piper.js:88 [Piper] Using proper espeak-ng phonemizer via piper-wasm
piper.js:112 [Piper] Warming up synthesis engine...
piper.js:116 [Piper] Warmup complete
piper.js:96 ‚úÖ Piper voice en_US-lessac-medium loaded successfully with espeak-ng phonemizer
modelOrchestrator.js:92 ‚úÖ Piper TTS loaded
modelOrchestrator.js:96 [ModelOrchestrator] Switching WebLLM to voice therapy mode...
modelOrchestrator.js:101 ‚úÖ [ModelOrchestrator] Voice Therapy tab ready
modelOrchestrator.js:102 üìä Memory footprint: Whisper WebGPU (39MB) + Piper (200MB) + WebLLM (shared) ‚âà ~250MB new
voicePipeline.js:49 [VoicePipeline] Initializing...
voicePipeline.js:59 [VoicePipeline] Initializing VAD...
vad.js:62 [VAD] Initializing Voice Activity Detector...
vad.js:69 [VAD] Loading model from cache
vad.js:87 [VAD] Creating ONNX Runtime session...
client:495 [vite] connecting...
client:495 [vite] connecting...
client:495 [vite] connecting...
client:618 [vite] connected.
client:618 [vite] connected.
client:618 [vite] connected.
installHook.js:1 2026-01-29 16:50:04.738604 [W:onnxruntime:Default, cpuid_info.cc:91 LogEarlyWarning] Unknown CPU vendor. cpuinfo_vendor value: 0
overrideMethod @ installHook.js:1
Bi @ ort.bundle.min.mjs?v=e2aba83d:14
$func12058 @ ort-wasm-simd-threaded.jsep.wasm:0x100dc44
$func1876 @ ort-wasm-simd-threaded.jsep.wasm:0x24ae72
$func855 @ ort-wasm-simd-threaded.jsep.wasm:0xc8c52
$func11987 @ ort-wasm-simd-threaded.jsep.wasm:0x1006a9e
$func1123 @ ort-wasm-simd-threaded.jsep.wasm:0x118d96
$func89 @ ort-wasm-simd-threaded.jsep.wasm:0xe826
$func13495 @ ort-wasm-simd-threaded.jsep.wasm:0x11845c1
$func118 @ ort-wasm-simd-threaded.jsep.wasm:0x16192
$func179 @ ort-wasm-simd-threaded.jsep.wasm:0x23783
$func4008 @ ort-wasm-simd-threaded.jsep.wasm:0x57b387
$func4153 @ ort-wasm-simd-threaded.jsep.wasm:0x5ca5c9
$func2337 @ ort-wasm-simd-threaded.jsep.wasm:0x2da863
$func14461 @ ort-wasm-simd-threaded.jsep.wasm:0x12e4a58
$Ga @ ort-wasm-simd-threaded.jsep.wasm:0x96032f
k.<computed> @ ort.bundle.min.mjs?v=e2aba83d:14
Ea.r._OrtInit @ ort.bundle.min.mjs?v=e2aba83d:14
_g @ ort.bundle.min.mjs?v=e2aba83d:2797
Ir @ ort.bundle.min.mjs?v=e2aba83d:2797
lc @ ort.bundle.min.mjs?v=e2aba83d:2797
await in lc
init @ ort.bundle.min.mjs?v=e2aba83d:2797
jp @ ort.bundle.min.mjs?v=e2aba83d:6
Qi @ ort.bundle.min.mjs?v=e2aba83d:6
create @ ort.bundle.min.mjs?v=e2aba83d:6
init @ vad.js:88
await in init
initialize @ voicePipeline.js:61
(anonymous) @ VoiceContext.jsx:71
await in (anonymous)
(anonymous) @ VoiceTherapy.jsx:46
commitHookEffectListMount @ chunk-YZVM2MHU.js?v=e2aba83d:16915
commitPassiveMountOnFiber @ chunk-YZVM2MHU.js?v=e2aba83d:18156
commitPassiveMountEffects_complete @ chunk-YZVM2MHU.js?v=e2aba83d:18129
commitPassiveMountEffects_begin @ chunk-YZVM2MHU.js?v=e2aba83d:18119
commitPassiveMountEffects @ chunk-YZVM2MHU.js?v=e2aba83d:18109
flushPassiveEffectsImpl @ chunk-YZVM2MHU.js?v=e2aba83d:19490
flushPassiveEffects @ chunk-YZVM2MHU.js?v=e2aba83d:19447
commitRootImpl @ chunk-YZVM2MHU.js?v=e2aba83d:19416
commitRoot @ chunk-YZVM2MHU.js?v=e2aba83d:19277
performSyncWorkOnRoot @ chunk-YZVM2MHU.js?v=e2aba83d:18895
flushSyncCallbacks @ chunk-YZVM2MHU.js?v=e2aba83d:9119
(anonymous) @ chunk-YZVM2MHU.js?v=e2aba83d:18627
vad.js:125 [VAD] States reset
vad.js:99 [VAD] Initialized successfully
vad.js:100 [VAD] Model size: 2.21 MB
voicePipeline.js:62 ‚úÖ VAD initialized
voicePipeline.js:70 ‚úÖ Voice pipeline initialized
VoiceContext.jsx:581 Loaded 27 sessions from history
VoiceContext.jsx:79 ‚úÖ [VoiceContext] Voice models initialized successfully
VoiceContext.jsx:233 [VoiceContext] Starting voice therapy session...
audioRecorder.js:48 ‚úÖ Audio recorder initialized
audioRecorder.js:49 üìä Sample rate: 16000Hz
voicePipeline.js:337 [VoicePipeline] Starting voice therapy session...
audioRecorder.js:48 ‚úÖ Audio recorder initialized
audioRecorder.js:49 üìä Sample rate: 16000Hz
voicePipeline.js:345 ‚úÖ Voice therapy session started
VoiceContext.jsx:247 ‚úÖ Voice therapy session started
VoiceContext.jsx:537 [VoiceContext] Starting recording...
audioRecorder.js:263 ‚úÖ Using MIME type: audio/webm;codecs=opus
audioRecorder.js:107 üé§ Recording started
VoiceContext.jsx:550 ‚úÖ Recording started
VoiceContext.jsx:468 [VoiceContext] Stopping recording and processing...
audioRecorder.js:138 üìä Recording duration: 5.2s
audioRecorder.js:142 üì¶ Audio blob size: 81.0 KB
audioRecorder.js:150 ‚úÖ Processed 81600 samples (5.1s)
VoiceContext.jsx:495 [VoiceContext] Processing audio...
voicePipeline.js:127 üéØ [VoicePipeline] Starting voice-to-voice processing...
voicePipeline.js:130 üé§ Step 1: Transcribing speech with WebGPU...
whisperWebGPU.js:230 [WhisperWebGPU] Transcribing 81600 samples...
whisperWebGPU.js:237 The powerPreference option is currently ignored when calling requestAdapter() on Windows. See https://crbug.com/369219127
$r @ ort.bundle.min.mjs?v=e2aba83d:2827
ac @ ort.bundle.min.mjs?v=e2aba83d:2827
init @ ort.bundle.min.mjs?v=e2aba83d:2827
await in init
Lp @ ort.bundle.min.mjs?v=e2aba83d:6
Fi @ ort.bundle.min.mjs?v=e2aba83d:6
await in Fi
create @ ort.bundle.min.mjs?v=e2aba83d:6
createInferenceSession @ @huggingface_transformers.js?v=e2aba83d:4169
await in createInferenceSession
wrap @ @huggingface_transformers.js?v=e2aba83d:22293
get matmul @ @huggingface_transformers.js?v=e2aba83d:22347
matmul @ @huggingface_transformers.js?v=e2aba83d:32264
spectrogram @ @huggingface_transformers.js?v=e2aba83d:28236
_extract_fbank_features @ @huggingface_transformers.js?v=e2aba83d:22035
_call @ @huggingface_transformers.js?v=e2aba83d:22087
closure @ @huggingface_transformers.js?v=e2aba83d:29282
_call @ @huggingface_transformers.js?v=e2aba83d:22226
closure @ @huggingface_transformers.js?v=e2aba83d:29282
_call_whisper @ @huggingface_transformers.js?v=e2aba83d:23365
await in _call_whisper
_call @ @huggingface_transformers.js?v=e2aba83d:23276
closure @ @huggingface_transformers.js?v=e2aba83d:29282
transcribe @ whisperWebGPU.js:237
processVoiceInput @ voicePipeline.js:132
(anonymous) @ VoiceContext.jsx:497
await in (anonymous)
callCallback2 @ chunk-YZVM2MHU.js?v=e2aba83d:3674
invokeGuardedCallbackDev @ chunk-YZVM2MHU.js?v=e2aba83d:3699
invokeGuardedCallback @ chunk-YZVM2MHU.js?v=e2aba83d:3733
invokeGuardedCallbackAndCatchFirstError @ chunk-YZVM2MHU.js?v=e2aba83d:3736
executeDispatch @ chunk-YZVM2MHU.js?v=e2aba83d:7014
processDispatchQueueItemsInOrder @ chunk-YZVM2MHU.js?v=e2aba83d:7034
processDispatchQueue @ chunk-YZVM2MHU.js?v=e2aba83d:7043
dispatchEventsForPlugins @ chunk-YZVM2MHU.js?v=e2aba83d:7051
(anonymous) @ chunk-YZVM2MHU.js?v=e2aba83d:7174
batchedUpdates$1 @ chunk-YZVM2MHU.js?v=e2aba83d:18913
batchedUpdates @ chunk-YZVM2MHU.js?v=e2aba83d:3579
dispatchEventForPluginEventSystem @ chunk-YZVM2MHU.js?v=e2aba83d:7173
dispatchEventWithEnableCapturePhaseSelectiveHydrationWithoutDiscreteEventReplay @ chunk-YZVM2MHU.js?v=e2aba83d:5478
dispatchEvent @ chunk-YZVM2MHU.js?v=e2aba83d:5472
dispatchDiscreteEvent @ chunk-YZVM2MHU.js?v=e2aba83d:5449
whisperWebGPU.js:247 [WhisperWebGPU] ‚úÖ Transcribed in 3455ms (1.5x realtime)
whisperWebGPU.js:248 [WhisperWebGPU] Result: " Hello, I want to know about mental health."
voicePipeline.js:136 ‚úÖ Transcription: "Hello, I want to know about mental health." (3456ms)
voicePipeline.js:140 üìä Whisper using: WASM
voicePipeline.js:147 ü§ñ Step 2: Generating AI response with streaming TTS...
webllm.js:109 üìã [TASK] Generating streaming response for voice... 
webllm.js:109 ‚ÑπÔ∏è [INFO] [Streaming] Sentence ready: "Mental health is a vital topic, and it's amazing how many people struggle with their mental well-being." 
voicePipeline.js:163 üó£Ô∏è Synthesizing sentence: "Mental health is a vital topic, and it's amazing how many people struggle with their mental well-being."
piper.js:192 üó£Ô∏è Synthesizing speech with espeak-ng phonemizer: "Mental health is a vital topic, and it's amazing h..."
piper.js:139 [Piper] Synthesizing: "Mental health is a vital topic, and it's amazing h..."
piper.js:207 ‚úÖ Synthesis complete: 246874 samples (5143.0s)
piper.js:208 [Piper] Phonemes used: ^ _ m _ Àà _ …õ _ n _ t _ …ô _ l _   _ h _ Àà _ …õ _ l _ Œ∏ _   _ …™ _ z _   _ …ê _   _ v _ Àà _ a _ …™ _ …æ _ …ô _ l _   _ t _ Àà _ …ë _ Àê _ p _ …™ _ k _ , _   _ √¶ _ n _ d _   _ …™ _ t _ s _   _ …ê _ m _ Àà _ e _ …™ _ z _ …™ _ ≈ã _   _ h _ Àå _ a _  ä _   _ m _ Àà _ …õ _ n _ i _   _ p _ Àà _ i _ Àê _ p _ …ô _ l _   _ s _ t _ …π _ Àà _  å _ …° _ …ô _ l _   _ w _ …™ _ √∞ _   _ √∞ _ …õ _ …π _   _ m _ Àà _ …õ _ n _ t _ …ô _ l _   _ w _ Àà _ …õ _ l _ b _ Àà _ i _ Àê _ …™ _ ≈ã _ . _ $
voicePipeline.js:172 ‚úÖ Sentence synthesized (5254ms)
webllm.js:109 ‚ÑπÔ∏è [INFO] [Streaming] Sentence ready: "You're taking the first step by acknowledging your interest, which is a huge step towards understanding and taking care of your mental health." 
voicePipeline.js:163 üó£Ô∏è Synthesizing sentence: "You're taking the first step by acknowledging your interest, which is a huge step towards understanding and taking care of your mental health."
piper.js:192 üó£Ô∏è Synthesizing speech with espeak-ng phonemizer: "You're taking the first step by acknowledging your..."
piper.js:139 [Piper] Synthesizing: "You're taking the first step by acknowledging your..."
piper.js:207 ‚úÖ Synthesis complete: 330466 samples (6884.0s)
piper.js:208 [Piper] Phonemes used: ^ _ j _  ä _ …π _   _ t _ Àà _ e _ …™ _ k _ …™ _ ≈ã _   _ √∞ _ …ô _   _ f _ Àà _ …ú _ Àê _ s _ t _   _ s _ t _ Àà _ …õ _ p _   _ b _ a _ …™ _   _ …ê _ k _ n _ Àà _ …ë _ Àê _ l _ …™ _ d _  í _ …™ _ ≈ã _   _ j _  ä _ …π _   _ Àà _ …™ _ n _ t _ …π _ …õ _ s _ t _ , _   _ w _ Àå _ …™ _ t _  É _   _ …™ _ z _   _ …ê _   _ h _ j _ Àà _ u _ Àê _ d _  í _   _ s _ t _ Àà _ …õ _ p _   _ t _ …ô _ w _ Àà _ …î _ Àê _ …π _ d _ z _   _ Àå _  å _ n _ d _ …ö _ s _ t _ Àà _ √¶ _ n _ d _ …™ _ ≈ã _   _ √¶ _ n _ d _   _ t _ Àà _ e _ …™ _ k _ …™ _ ≈ã _   _ k _ Àà _ …õ _ …π _   _  å _ v _   _ j _  ä _ …π _   _ m _ Àà _ …õ _ n _ t _ …ô _ l _   _ h _ Àà _ …õ _ l _ Œ∏ _ . _ $
voicePipeline.js:172 ‚úÖ Sentence synthesized (5818ms)
webllm.js:109 ‚úÖ [SUCCESS] Streaming complete: 246 chars 
voicePipeline.js:191 ‚úÖ AI Response: "Mental health is a vital topic, and it's amazing how many people struggle with their mental well-being. You're taking the first step by acknowledging your interest, which is a huge step towards understanding and taking care of your mental health." (52041ms)
voicePipeline.js:194 üîä Step 3: Playing audio response...
voicePipeline.js:305 üîä Playing 26.2s of audio
voicePipeline.js:296 üîá Audio playback complete
voicePipeline.js:204 ‚úÖ Audio playback complete (26201ms)
voicePipeline.js:214 ‚úÖ [VoicePipeline] Complete! Total: 81699ms
voicePipeline.js:215 üìä Breakdown: STT=3456ms, LLM+TTS=52041ms
VoiceContext.jsx:523 ‚úÖ Audio processed successfully
VoiceContext.jsx:537 [VoiceContext] Starting recording...
audioRecorder.js:263 ‚úÖ Using MIME type: audio/webm;codecs=opus
audioRecorder.js:107 üé§ Recording started
VoiceContext.jsx:550 ‚úÖ Recording started
VoiceContext.jsx:468 [VoiceContext] Stopping recording and processing...
audioRecorder.js:138 üìä Recording duration: 5.5s
audioRecorder.js:142 üì¶ Audio blob size: 86.7 KB
audioRecorder.js:150 ‚úÖ Processed 87360 samples (5.5s)
VoiceContext.jsx:495 [VoiceContext] Processing audio...
voicePipeline.js:127 üéØ [VoicePipeline] Starting voice-to-voice processing...
voicePipeline.js:130 üé§ Step 1: Transcribing speech with WebGPU...
whisperWebGPU.js:230 [WhisperWebGPU] Transcribing 87360 samples...
whisperWebGPU.js:247 [WhisperWebGPU] ‚úÖ Transcribed in 3110ms (1.8x realtime)
whisperWebGPU.js:248 [WhisperWebGPU] Result: " Okay, thank you. So I want to know that what exactly we can do."
voicePipeline.js:136 ‚úÖ Transcription: "Okay, thank you. So I want to know that what exactly we can do." (3111ms)
voicePipeline.js:140 üìä Whisper using: WASM
voicePipeline.js:147 ü§ñ Step 2: Generating AI response with streaming TTS...
webllm.js:109 üìã [TASK] Generating streaming response for voice... 
webllm.js:109 ‚ÑπÔ∏è [INFO] [Streaming] Sentence ready: "What we can do is start small, be kind to ourselves, and take tiny steps towards healing." 
voicePipeline.js:163 üó£Ô∏è Synthesizing sentence: "What we can do is start small, be kind to ourselves, and take tiny steps towards healing."
piper.js:192 üó£Ô∏è Synthesizing speech with espeak-ng phonemizer: "What we can do is start small, be kind to ourselve..."
piper.js:139 [Piper] Synthesizing: "What we can do is start small, be kind to ourselve..."
piper.js:207 ‚úÖ Synthesis complete: 249660 samples (5201.0s)
piper.js:208 [Piper] Phonemes used: ^ _ w _ Àå _  å _ t _   _ w _ i _ Àê _   _ k _ √¶ _ n _   _ d _ Àà _ u _ Àê _   _ …™ _ z _   _ s _ t _ Àà _ …ë _ Àê _ …π _ t _   _ s _ m _ Àà _ …î _ Àê _ l _ , _   _ b _ i _ Àê _   _ k _ Àà _ a _ …™ _ n _ d _   _ t _  ä _   _ a _  ä _ …ö _ s _ Àà _ …õ _ l _ v _ z _ , _   _ √¶ _ n _ d _   _ t _ Àà _ e _ …™ _ k _   _ t _ Àà _ a _ …™ _ n _ i _   _ s _ t _ Àà _ …õ _ p _ s _   _ t _ …ô _ w _ Àà _ …î _ Àê _ …π _ d _ z _   _ h _ Àà _ i _ Àê _ l _ …™ _ ≈ã _ . _ $
voicePipeline.js:172 ‚úÖ Sentence synthesized (4264ms)
webllm.js:109 ‚ÑπÔ∏è [INFO] [Streaming] Sentence ready: "We can try to practice self-compassion, like talking to a friend, and acknowledge that we're doing the best we can." 
voicePipeline.js:163 üó£Ô∏è Synthesizing sentence: "We can try to practice self-compassion, like talking to a friend, and acknowledge that we're doing the best we can."
piper.js:192 üó£Ô∏è Synthesizing speech with espeak-ng phonemizer: "We can try to practice self-compassion, like talki..."
piper.js:139 [Piper] Synthesizing: "We can try to practice self-compassion, like talki..."
piper.js:207 ‚úÖ Synthesis complete: 274738 samples (5723.0s)
piper.js:208 [Piper] Phonemes used: ^ _ w _ i _ Àê _   _ k _ √¶ _ n _   _ t _ …π _ Àà _ a _ …™ _   _ t _ …ô _   _ p _ …π _ Àà _ √¶ _ k _ t _ …™ _ s _   _ s _ Àà _ …õ _ l _ f _ k _ …ô _ m _ p _ Àà _ √¶ _  É _ …ô _ n _ , _   _ l _ Àà _ a _ …™ _ k _   _ t _ Àà _ …î _ Àê _ k _ …™ _ ≈ã _   _ t _  ä _   _ …ê _   _ f _ …π _ Àà _ …õ _ n _ d _ , _   _ √¶ _ n _ d _   _ …ê _ k _ n _ Àà _ …ë _ Àê _ l _ …™ _ d _  í _   _ √∞ _ √¶ _ t _   _ w _ …™ _ …π _   _ d _ Àå _ u _ Àê _ …™ _ ≈ã _   _ √∞ _ …ô _   _ b _ Àà _ …õ _ s _ t _   _ w _ i _ Àê _   _ k _ Àà _ √¶ _ n _ . _ $
voicePipeline.js:172 ‚úÖ Sentence synthesized (5108ms)
webllm.js:109 ‚úÖ [SUCCESS] Streaming complete: 205 chars 
voicePipeline.js:191 ‚úÖ AI Response: "What we can do is start small, be kind to ourselves, and take tiny steps towards healing. We can try to practice self-compassion, like talking to a friend, and acknowledge that we're doing the best we can." (41216ms)
voicePipeline.js:194 üîä Step 3: Playing audio response...
voicePipeline.js:305 üîä Playing 23.8s of audio
voicePipeline.js:296 üîá Audio playback complete
voicePipeline.js:204 ‚úÖ Audio playback complete (23795ms)
voicePipeline.js:214 ‚úÖ [VoicePipeline] Complete! Total: 68124ms
voicePipeline.js:215 üìä Breakdown: STT=3111ms, LLM+TTS=41216ms
VoiceContext.jsx:523 ‚úÖ Audio processed successfully
VoiceContext.jsx:267 [VoiceContext] Ending voice therapy session...
voicePipeline.js:352 [VoicePipeline] Ending voice therapy session...
audioRecorder.js:326 üóëÔ∏è Audio recorder cleaned up
voicePipeline.js:367 ‚úÖ Voice therapy session ended
voiceSessionStorage.js:114 [VoiceStorage] Session saved with ID: 28
VoiceContext.jsx:311 ‚úÖ Session saved with ID: 28
VoiceContext.jsx:581 Loaded 28 sessions from history
VoiceContext.jsx:339 ‚úÖ Voice therapy session ended
